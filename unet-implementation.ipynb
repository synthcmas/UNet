{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport torch, torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data.dataset import Dataset\nimport torch.nn.functional as F\nfrom PIL import Image","metadata":{"_uuid":"ce0e68ed-ac63-4f89-9056-1f7d00730679","_cell_guid":"e6bbbc27-9320-4320-80c8-20a49890394a","collapsed":false,"id":"zqvxvmM1gWnq","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir('/kaggle')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir 'train'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! unzip 'input/data-science-bowl-2018/stage1_train.zip' -d 'stage1_train' ","metadata":{"_uuid":"b8456d73-7df9-4909-b134-a03040d2f7c0","_cell_guid":"01f85b62-7747-45e5-a07e-629737c4966a","collapsed":false,"id":"dvPlEySsQfRY","outputId":"3f388928-a9a4-49a4-cce0-de2cb3c1f328","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir 'stage1_test'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! unzip 'input/data-science-bowl-2018/stage1_test.zip' -d 'stage1_test'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n  def __init__(self, data, transforms = None):\n\n    self.data = data\n    self.transformations = transforms\n    self.len = len(data)\n\n  def __getitem__(self, index):\n\n    img_name = os.listdir(f'{self.data[index]}/images')\n    img = Image.open(f'{self.data[index]}/images/{img_name[0]}')\n    img_tensor = self.transformations(img)\n\n    gt_mask = torch.zeros((1,256,256))\n\n    masks = os.listdir(f'{self.data[index]}/masks')\n    wm_masks = torch.zeros((len(masks),256,256))\n\n    for i,mask in enumerate(masks):\n      mask_img = Image.open(f'{self.data[index]}/masks/{mask}')\n      mask_img = self.transformations(mask_img)\n\n      gt_mask += mask_img\n      wm_masks[i] = mask_img[0]\n\n    weight_map = make_weight_map(wm_masks.numpy())\n\n    return img_tensor, gt_mask, weight_map\n\n  def __len__(self):\n\n    return self.len","metadata":{"_uuid":"d0ec3d2b-1189-4c55-a5c7-09963bb64d01","_cell_guid":"dab38b29-41a7-4159-bc5b-e304cbd14d42","collapsed":false,"id":"2fYnV32v7y1H","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.segmentation import find_boundaries\n\ndef make_weight_map(masks):\n\n  w0 = 10\n  sigma = 5\n\n  n_masks, n_rows, n_cols = masks.shape\n\n  dist_map = np.zeros((n_rows*n_cols, n_masks))\n\n  X1, Y1 = np.meshgrid(np.arange(n_rows),np.arange(n_cols))\n\n  X1, Y1 = np.c_[X1.ravel(), Y1.ravel()].T\n\n  for i, mask in enumerate(masks):\n    boundaries = find_boundaries(mask, mode = 'inner')\n    X2, Y2 = np.nonzero(boundaries)\n    xSum = (X2.reshape(-1,1) - X1.reshape(1,-1))**2\n    ySum = (Y2.reshape(-1,1) - Y1.reshape(1,-1))**2\n    dist_map[:,i] = np.sqrt(xSum + ySum).min(axis = 0)\n\n  if (n_masks == 1):\n    d1 = dist_map.ravel()\n    border_loss = w0*np.exp((-(d1**2))/(2*(sigma**2)))\n\n  else:\n    for i,arr in enumerate(dist_map):\n      dist_map[i,:] = np.sort(arr)\n\n    d1 = dist_map[:,0]\n    d2 = dist_map[:,1]\n    border_loss = w0*np.exp(((-(d1 + d2)**2))/(2*(sigma**2)))\n\n  wb_Loss = np.zeros((n_rows, n_cols))\n  wb_Loss[X1, Y1] = border_loss\n\n  class_Loss = np.zeros((n_rows, n_cols))\n\n  w_1 = 1 - masks.sum()/(class_Loss.size)\n  w_0 = 1 - w_1\n\n  class_Loss[masks.sum(0) == 1] = w_1\n  class_Loss[masks.sum(0) == 0] = w_0\n\n  total_Loss = class_Loss + wb_Loss\n\n  return torch.from_numpy(total_Loss).reshape(1, n_rows, n_cols)","metadata":{"_uuid":"8fc7687d-f7e7-43b4-b775-ce2ee4f60095","_cell_guid":"c446e470-7b48-4bbf-a2bc-f5a56d520d53","collapsed":false,"id":"1S00C_vUTYtJ","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimages = glob.glob('stage1_train/' + '*')\nimages = np.array(images)","metadata":{"_uuid":"2b92d76d-94da-4227-a3d3-ac55ea29352a","_cell_guid":"da4fa234-9de8-4d57-82c9-da47f8e49026","collapsed":false,"id":"Su7krim2BTxL","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.shuffle(images)\nshuffled_images = list(images)\ntrain_images = shuffled_images[:int(0.9*len(shuffled_images) + 1)]\nvalidation_images = shuffled_images[int(0.9*len(shuffled_images) + 1):int(len(shuffled_images) + 1)]","metadata":{"_uuid":"19534239-9a11-423e-a130-d3678cc10f92","_cell_guid":"be3e248f-0ab8-4acf-b66a-1122de16479f","collapsed":false,"id":"WEaEEWeJAIFJ","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformations = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor()])","metadata":{"_uuid":"17d83801-9c96-43b6-9542-63f22ae3fb28","_cell_guid":"07882f35-247e-4ad0-8ea6-0fa0a9410c80","collapsed":false,"id":"sSbwjh1SJ7NJ","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_dataset_train = CustomDataset(train_images, transformations)\ncustom_dataset_validation = CustomDataset(validation_images, transformations)","metadata":{"_uuid":"b05e5847-4604-4e75-a4d7-1b0e5d9417b9","_cell_guid":"7bd13d77-2264-4824-b877-7eaa7845eab0","collapsed":false,"id":"MlrGpHDLJq9v","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainloader = torch.utils.data.DataLoader(dataset = custom_dataset_train, \n                                          batch_size = 8, shuffle = True)\nvalidationloader = torch.utils.data.DataLoader(dataset = custom_dataset_validation, \n                                               batch_size = 8, shuffle = True)","metadata":{"_uuid":"ff834461-e464-4847-8a2c-9aba74a687ac","_cell_guid":"64d36802-202d-4172-8ba6-8bb9ecbbcc1f","collapsed":false,"id":"4Ge-9CQxXzjh","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n\n    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n        \n      block = nn.Sequential(\n              nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, \n                                    out_channels=out_channels, padding = 1),\n              nn.BatchNorm2d(out_channels),\n              nn.ReLU(),\n              nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, \n                                    out_channels=out_channels, padding = 1),\n              nn.BatchNorm2d(out_channels),\n              nn.ReLU(),\n              )\n      return block\n\n    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n         \n      block = nn.Sequential(\n              nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, \n                                    out_channels=mid_channel, padding = 1),\n              nn.BatchNorm2d(mid_channel),\n              nn.ReLU(), \n              nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, \n                                    out_channels=mid_channel, padding = 1),\n              nn.BatchNorm2d(mid_channel),\n              nn.ReLU(),       \n              nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, \n                                             kernel_size=3, stride=2, padding=1, output_padding=1)\n              )\n      return  block\n\n    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n        \n      block = nn.Sequential(\n              nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, \n                                out_channels=mid_channel, padding = 1),\n              nn.BatchNorm2d(mid_channel),\n              nn.ReLU(),  \n              nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, \n                                out_channels=mid_channel, padding = 1),\n              nn.BatchNorm2d(mid_channel),\n              nn.ReLU(),\n              nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, \n                                out_channels=out_channels, padding= 1),\n              nn.Sigmoid() \n              )\n      \n      return block\n\n    def __init__(self, in_channel, out_channel):\n      super(UNet, self).__init__()\n\n      #Encode\n      self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n      self.conv_maxpool1 = nn.MaxPool2d(kernel_size=2)\n      self.conv_encode2 = self.contracting_block(64, 128)\n      self.conv_maxpool2 = nn.MaxPool2d(kernel_size=2)\n      self.conv_encode3 = self.contracting_block(128, 256)\n      self.conv_maxpool3 = nn.MaxPool2d(kernel_size=2)\n\n      # Bottleneck\n      self.bottleneck =  nn.Sequential(\n                         nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512, padding = 1),\n                         nn.BatchNorm2d(512),\n                         nn.ReLU(), \n                         nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding = 1),\n                         nn.BatchNorm2d(512),\n                         nn.ReLU(),\n                         nn.ConvTranspose2d(in_channels=512, out_channels=256, \n                                                     kernel_size=3, stride=2, padding=1, output_padding=1)\n                         )\n      # Decode\n      self.conv_decode3 = self.expansive_block(512, 256, 128)\n      self.conv_decode2 = self.expansive_block(256, 128, 64)\n      self.final_layer = self.final_block(128, 64, out_channel)\n\n    def crop_and_concat(self, upsampled, bypass, crop=False):\n        \n      if crop:\n        c = (bypass.size()[2] - upsampled.size()[2]) // 2\n        bypass = F.pad(bypass, (-c, -c, -c, -c))\n      \n      return torch.cat((upsampled, bypass), 1)\n\n    def forward(self, x):\n      # Encode\n      encode_block1 = self.conv_encode1(x)\n      encode_pool1 = self.conv_maxpool1(encode_block1)\n      encode_block2 = self.conv_encode2(encode_pool1)\n      encode_pool2 = self.conv_maxpool2(encode_block2)\n      encode_block3 = self.conv_encode3(encode_pool2)\n      encode_pool3 = self.conv_maxpool3(encode_block3)\n\n      # Bottleneck\n      bottleneck1 = self.bottleneck(encode_pool3)\n\n      # Decode\n      decode_block3 = self.crop_and_concat(bottleneck1, encode_block3)\n      cat_layer2 = self.conv_decode3(decode_block3)\n      decode_block2 = self.crop_and_concat(cat_layer2, encode_block2)\n      cat_layer1 = self.conv_decode2(decode_block2)\n      decode_block1 = self.crop_and_concat(cat_layer1, encode_block1)\n      final_layer = self.final_layer(decode_block1)\n      \n      return final_layer","metadata":{"_uuid":"994d12cd-15b9-4bd7-881b-fa48a46a6459","_cell_guid":"ffcb9ff0-ab60-45e2-b1b7-89fc78e5f4d6","collapsed":false,"id":"3XPFK17spcgw","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"4a280d7b-2023-4253-8c5b-bdcc32090a52","_cell_guid":"068b47cf-9e24-4d0e-a4ce-5e4407fb0193","collapsed":false,"id":"aBl3hTd-_Umu","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet = UNet(4, 1).to(device)","metadata":{"_uuid":"c5127aa5-d9bc-4635-adb3-a16675af1577","_cell_guid":"a89ec80f-e038-48ca-82c8-e8f8c79829d5","collapsed":false,"id":"sAfL3I9AyrUX","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(unet.parameters(), lr = 0.01)\nepochs = 20","metadata":{"_uuid":"6b75bb35-67cc-43e0-a0a6-8531895bc9c9","_cell_guid":"07206800-6d9c-4577-99b1-14c578927a9a","collapsed":false,"id":"9OqojCI37Ipk","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"costs_train = []\ncosts_validation = []\n\nfor epoch in range(epochs):\n\n  for i, (images, gt_masks, wt_maps) in enumerate(trainloader):\n    \n    batch_size = images.shape[0]\n    \n    images = images.to(device)    \n    gt_masks = gt_masks.to(device)\n    wt_maps = wt_maps.to(device)\n\n    train_out = unet(images)\n    \n    train_out = torch.clip(train_out, 0.05, 0.95)\n\n    if (gt_masks.requires_grad != True):\n      gt_masks.requires_grad = True\n    \n    if (wt_maps.requires_grad != True):\n      wt_maps.requires_grad = True\n\n    train_loss = -((wt_maps.mul(torch.log(train_out.mul(gt_masks) + (1-train_out).mul(1-gt_masks)))).sum())/(batch_size)\n    costs_train.append(train_loss.item())\n\n    if (((i+1)%(len(validationloader))) == 1):\n      valid_iter = iter(validationloader)\n\n    valid_images, gt_masks_valid, wt_maps_valid = next(valid_iter)\n\n    valid_images = valid_images.to(device)\n    gt_masks_valid = gt_masks_valid.to(device)\n    wt_maps_valid = wt_maps_valid.to(device)\n\n    valid_out = unet(valid_images)\n    valid_out = torch.clip(valid_out, 0.05, 0.95)\n\n    valid_loss = -((wt_maps_valid.mul(torch.log(valid_out.mul(gt_masks_valid) + (1-valid_out).mul(1-gt_masks_valid)))).sum())/(batch_size)\n    costs_validation.append(valid_loss.item())\n\n    optimizer.zero_grad()\n    train_loss.backward()\n    optimizer.step() \n\n    if (((i+1) %10) == 0):\n      print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(trainloader)}], Training loss: {train_loss.item()}, Validation loss: {valid_loss.item()} ')\n\nplt.plot(np.arange(1, len(costs_train)+1), costs_train, label = 'Training Loss')\nplt.plot(np.arange(1, len(costs_validation)+1), costs_validation, label = 'Validation Loss' )\nplt.legend()\nplt.show()","metadata":{"_uuid":"ff4ca0b8-d98d-420e-8eb7-8d9c973fe8e5","_cell_guid":"16d6caff-e427-4d79-a72b-34ca4b022d78","collapsed":false,"id":"WgQRcyE47ZnQ","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}